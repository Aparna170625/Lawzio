# translation_module.py

from googletrans import Translator as GoogleTranslator
from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline
import torch

# Initialize models
# (Load heavy models only when needed)

# 1. Google Translate (API-free version)
def translate_google(text, dest_language='en'):
    translator = GoogleTranslator()
    translation = translator.translate(text, dest=dest_language)
    return translation.text

# 2. IndicTrans (for Indian Languages)
def translate_indictrans(text, src_lang="hin", tgt_lang="eng"):
    model_name = "ai4bharat/indictrans2-en-indic-1B"  # Smaller available model
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

    inputs = tokenizer(f"{src_lang}>>{tgt_lang} {text}", return_tensors="pt")
    outputs = model.generate(**inputs, max_length=512)
    translated = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]
    return translated

# 3. NLLB-200 (Meta AI)
def translate_nllb(text, src_lang="hin_Deva", tgt_lang="eng_Latn"):
    model_name = "facebook/nllb-200-distilled-600M"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

    inputs = tokenizer(text, return_tensors="pt", src_lang=src_lang)
    generated_tokens = model.generate(**inputs, forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang])
    translation = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]
    return translation

# 4. mBART / mT5 (Multilingual Summarization + Translation)
def translate_mbart(text, src_lang="hi_IN", tgt_lang="en_XX"):
    model_name = "facebook/mbart-large-50-many-to-many-mmt"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSeq2SeqLM.from_pretrained(model_name)

    tokenizer.src_lang = src_lang
    encoded = tokenizer(text, return_tensors="pt")
    generated_tokens = model.generate(
        **encoded,
        forced_bos_token_id=tokenizer.lang_code_to_id[tgt_lang]
    )
    translated = tokenizer.batch_decode(generated_tokens, skip_special_tokens=True)[0]
    return translated

# Example Usage
if __name__ == "__main__":
    input_text = "यह एक कानूनी दस्तावेज़ है।"

    # Google Translate
    print("Google Translation:", translate_google(input_text, dest_language='en'))

    # IndicTrans
    print("IndicTrans Translation:", translate_indictrans(input_text, src_lang="hin", tgt_lang="eng"))

    # NLLB-200
    print("NLLB-200 Translation:", translate_nllb(input_text, src_lang="hin_Deva", tgt_lang="eng_Latn"))

    # mBART
    print("mBART Translation:", translate_mbart(input_text, src_lang="hi_IN", tgt_lang="en_XX"))
